"""
í—¤ë”© ê°ì§€ ì„œë¹„ìŠ¤ (í°íŠ¸ ê¸°ë°˜)

PDF í…ìŠ¤íŠ¸ ë¸”ë¡ì—ì„œ í°íŠ¸ í¬ê¸°, ìœ„ì¹˜, ìŠ¤íƒ€ì¼ì„ ë¶„ì„í•˜ì—¬
í—¤ë”©(ì œëª©)ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ëª©ì°¨ êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import re
import logging
from typing import List, Optional, Tuple
from dataclasses import dataclass

from app.models.pdf_models import TextBlock, DocumentAnalysis
from app.utils.config import settings

logger = logging.getLogger(__name__)


@dataclass
class TOCEntry:
    """ëª©ì°¨ í•­ëª©"""
    title: str
    level: int  # 1=ëŒ€ë‹¨ì›, 2=ì¤‘ë‹¨ì›, 3=ì†Œë‹¨ì›
    page_num: int
    font_size: float
    bbox_x0: float
    bbox_y0: float
    confidence: float = 1.0

    def to_dict(self):
        """Convert to dictionary for JSON serialization"""
        return {
            "title": self.title,
            "level": self.level,
            "pageNum": self.page_num,
            "fontSize": self.font_size,
            "bbox": {
                "x": self.bbox_x0,
                "y": self.bbox_y0
            },
            "confidence": round(self.confidence, 3)
        }


class HeadingDetector:
    """í—¤ë”© ê°ì§€ í´ë˜ìŠ¤"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.threshold_l1 = settings.HEADING_FONT_RATIO_L1  # Level 1 ì„ê³„ê°’ (1.8)
        self.threshold_l2 = settings.HEADING_FONT_RATIO_L2  # Level 2 ì„ê³„ê°’ (1.4)
        self.threshold_l3 = settings.HEADING_FONT_RATIO_L3  # Level 3 ì„ê³„ê°’ (1.2)

    def is_in_heading_position(
        self,
        block: TextBlock,
        page_width: float,
        page_height: float
    ) -> bool:
        """
        í—¤ë”©ì´ ì£¼ë¡œ ìœ„ì¹˜í•˜ëŠ” ì˜ì—­ì¸ì§€ í™•ì¸
        - í˜ì´ì§€ ì¢Œì¸¡ ìƒë‹¨ (x < pageWidth * 0.3)
        - ìƒë‹¨ ì˜ì—­ (y < 150pt)

        Args:
            block: í…ìŠ¤íŠ¸ ë¸”ë¡
            page_width: í˜ì´ì§€ ë„ˆë¹„
            page_height: í˜ì´ì§€ ë†’ì´

        Returns:
            ìœ„ì¹˜ ì¡°ê±´ ë§Œì¡± ì—¬ë¶€
        """
        # X ì¢Œí‘œ ì¡°ê±´: ì¢Œì¸¡ 30% ì˜ì—­
        is_left_side = block.bbox.x0 < page_width * 0.3

        # Y ì¢Œí‘œ ì¡°ê±´: ìƒë‹¨ 150pt ì´ë‚´ ë˜ëŠ” í˜ì´ì§€ ìƒë‹¨ 20% ì´ë‚´
        is_top_area = (block.bbox.y0 < 150) or (block.bbox.y0 < page_height * 0.2)

        # ë‘˜ ì¤‘ í•˜ë‚˜ë§Œ ë§Œì¡±í•´ë„ OK (ì¼ë¶€ PDFëŠ” ì¤‘ì•™ ì •ë ¬ ì œëª©ë„ ìˆìŒ)
        return is_left_side or is_top_area

    def is_heading_pattern(self, text: str) -> bool:
        """
        ì œëª© íŒ¨í„´ ë§¤ì¹­ (ì •ê·œì‹)

        íŒ¨í„´:
        - "1. ì„œë¡ "
        - "ì œ1ì¥", "ì œ 1 ì¥"
        - "Chapter 1"
        - "I. Introduction"
        - "1-1 ê°œë…"
        - "[ë‹¨ì›ëª…]"
        - "1) ì œëª©"

        Args:
            text: í…ìŠ¤íŠ¸ ë‚´ìš©

        Returns:
            íŒ¨í„´ ë§¤ì¹­ ì—¬ë¶€
        """
        patterns = [
            r'^\d+\.\s*.+',  # "1. ì„œë¡ "
            r'^ì œ\s*\d+\s*ì¥.+',  # "ì œ1ì¥"
            r'^Chapter\s+\d+',  # "Chapter 1"
            r'^[IVX]+\.\s*.+',  # "I. Introduction"
            r'^\d+-\d+',  # "1-1 ê°œë…"
            r'^\[.*\]',  # "[ë‹¨ì›ëª…]"
            r'^\d+\)\s*.+',  # "1) ì œëª©"
            r'^ì œ\s*\d+\s*ì ˆ',  # "ì œ1ì ˆ"
            r'^Section\s+\d+',  # "Section 1"
            r'^\d+\.\d+',  # "1.1"
        ]

        text_stripped = text.strip()

        for pattern in patterns:
            if re.match(pattern, text_stripped, re.IGNORECASE):
                return True

        return False

    def determine_heading_level(
        self,
        block: TextBlock,
        avg_font_size: float
    ) -> Optional[int]:
        """
        í—¤ë”© ë ˆë²¨ ê²°ì •

        Args:
            block: í…ìŠ¤íŠ¸ ë¸”ë¡
            avg_font_size: í‰ê·  í°íŠ¸ í¬ê¸°

        Returns:
            í—¤ë”© ë ˆë²¨ (1/2/3) ë˜ëŠ” None (í—¤ë”© ì•„ë‹˜)
        """
        if avg_font_size == 0:
            return None

        ratio = block.font.size / avg_font_size

        # Level 1 (ëŒ€ë‹¨ì›): fontSize >= avgFontSize * 1.8
        if ratio >= self.threshold_l1:
            return 1

        # Level 2 (ì¤‘ë‹¨ì›): fontSize >= avgFontSize * 1.4
        if ratio >= self.threshold_l2:
            return 2

        # Level 3 (ì†Œë‹¨ì›): fontSize >= avgFontSize * 1.2
        if ratio >= self.threshold_l3:
            return 3

        # ì„ê³„ê°’ ë¯¸ë§Œ
        return None

    def is_heading_candidate(
        self,
        block: TextBlock,
        avg_font_size: float,
        page_width: float,
        page_height: float
    ) -> Tuple[bool, Optional[int]]:
        """
        í—¤ë”© í›„ë³´ ì—¬ë¶€ íŒë‹¨ (ë³µí•© ì¡°ê±´)

        ì¡°ê±´:
        1. í°íŠ¸ í¬ê¸°ê°€ í‰ê· ë³´ë‹¤ í¼
        2. ë³¼ë“œì²´ ë˜ëŠ” íŠ¹ì • í°íŠ¸ ì‚¬ìš©
        3. ìœ„ì¹˜ ì¡°ê±´ (ì¢Œì¸¡ ìƒë‹¨)
        4. íŒ¨í„´ ë§¤ì¹­ (ì„ íƒì  ê°•í™”)

        Args:
            block: í…ìŠ¤íŠ¸ ë¸”ë¡
            avg_font_size: í‰ê·  í°íŠ¸ í¬ê¸°
            page_width: í˜ì´ì§€ ë„ˆë¹„
            page_height: í˜ì´ì§€ ë†’ì´

        Returns:
            (í—¤ë”© ì—¬ë¶€, í—¤ë”© ë ˆë²¨)
        """
        # 1. ë ˆë²¨ ê²°ì • (í°íŠ¸ í¬ê¸° ê¸°ë°˜)
        level = self.determine_heading_level(block, avg_font_size)

        if level is None:
            return False, None

        # 2. ì¶”ê°€ ì¡°ê±´ ì²´í¬

        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ì œì™¸ (1ê¸€ì ì´í•˜)
        if len(block.text.strip()) <= 1:
            return False, None

        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì œì™¸ (200ì ì´ìƒì€ ë³¸ë¬¸ì¼ ê°€ëŠ¥ì„± ë†’ìŒ)
        if len(block.text.strip()) > 200:
            return False, None

        # 3. ê°€ì¤‘ì¹˜ ê³„ì‚° (ì‹ ë¢°ë„)
        confidence = 0.5  # ê¸°ë³¸ ì‹ ë¢°ë„

        # ë³¼ë“œì²´ë©´ +0.2
        if block.font.is_bold:
            confidence += 0.2

        # ìœ„ì¹˜ ì¡°ê±´ ë§Œì¡±í•˜ë©´ +0.2
        if self.is_in_heading_position(block, page_width, page_height):
            confidence += 0.2

        # íŒ¨í„´ ë§¤ì¹­ ë§Œì¡±í•˜ë©´ +0.3
        if self.is_heading_pattern(block.text):
            confidence += 0.3

        # ìµœì†Œ ì‹ ë¢°ë„ 0.6 ì´ìƒì´ì–´ì•¼ í—¤ë”©ìœ¼ë¡œ ì¸ì •
        if confidence >= 0.6:
            return True, level
        else:
            return False, None

    def detect_headings_from_document(
        self,
        doc_analysis: DocumentAnalysis,
        use_reference_position: bool = True,
        reference_y_min: float = 65.0,
        reference_y_max: float = 75.0
    ) -> List[TOCEntry]:
        """
        ì „ì²´ ë¬¸ì„œì—ì„œ í—¤ë”© ê°ì§€ ë° ëª©ì°¨ ìƒì„± (ê±°ì§“ ì–‘ì„± ì œê±° í¬í•¨)

        Args:
            doc_analysis: ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ (PyMuPDF)
            use_reference_position: ì°¸ì¡° ìœ„ì¹˜ ê¸°ë°˜ í•„í„°ë§ ì‚¬ìš© ì—¬ë¶€
            reference_y_min: ì°¸ì¡° y ì¢Œí‘œ ìµœì†Œê°’
            reference_y_max: ì°¸ì¡° y ì¢Œí‘œ ìµœëŒ€ê°’

        Returns:
            ëª©ì°¨ í•­ëª© ë¦¬ìŠ¤íŠ¸
        """
        if use_reference_position:
            return self.detect_headings_by_reference_position(
                doc_analysis,
                reference_y_min,
                reference_y_max
            )
        else:
            toc_entries = self.detect_headings(doc_analysis)
            return self.filter_false_positives(toc_entries)

    def detect_headings(
        self,
        doc_analysis: DocumentAnalysis
    ) -> List[TOCEntry]:
        """
        ì „ì²´ ë¬¸ì„œì—ì„œ í—¤ë”© ê°ì§€ ë° ëª©ì°¨ ìƒì„±

        Args:
            doc_analysis: ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ (PyMuPDF)

        Returns:
            ëª©ì°¨ í•­ëª© ë¦¬ìŠ¤íŠ¸
        """
        toc_entries = []

        avg_font_size = doc_analysis.global_avg_font_size

        if avg_font_size == 0:
            logger.warning("í‰ê·  í°íŠ¸ í¬ê¸°ê°€ 0ì´ë¯€ë¡œ í—¤ë”© ê°ì§€ ë¶ˆê°€")
            return []

        logger.info(f"ì „ì²´ ë¬¸ì„œ í‰ê·  í°íŠ¸ í¬ê¸°: {avg_font_size:.2f}pt")

        # ê° í˜ì´ì§€ ìˆœíšŒ
        for page_analysis in doc_analysis.pages:
            page_num = page_analysis.page_num
            page_width = page_analysis.width
            page_height = page_analysis.height

            # ê° í…ìŠ¤íŠ¸ ë¸”ë¡ ìˆœíšŒ
            for block in page_analysis.text_blocks:
                is_heading, level = self.is_heading_candidate(
                    block,
                    avg_font_size,
                    page_width,
                    page_height
                )

                if is_heading and level:
                    # ì‹ ë¢°ë„ ê³„ì‚° (ê°„ë‹¨ ë²„ì „)
                    confidence = min(1.0, block.font.size / avg_font_size / 2.0)

                    toc_entry = TOCEntry(
                        title=block.text.strip(),
                        level=level,
                        page_num=page_num,
                        font_size=block.font.size,
                        bbox_x0=block.bbox.x0,
                        bbox_y0=block.bbox.y0,
                        confidence=confidence
                    )

                    toc_entries.append(toc_entry)

                    logger.info(
                        f"í—¤ë”© ê°ì§€: [{level}] '{block.text[:30]}...' "
                        f"(í˜ì´ì§€ {page_num}, {block.font.size:.1f}pt, "
                        f"ì‹ ë¢°ë„ {confidence:.2f})"
                    )

        logger.info(f"ì´ {len(toc_entries)}ê°œ í—¤ë”© ê°ì§€ ì™„ë£Œ")
        return toc_entries

    def build_toc_structure(
        self,
        toc_entries: List[TOCEntry]
    ) -> List[dict]:
        """
        ëª©ì°¨ êµ¬ì¡° ìƒì„± (ê³„ì¸µì  íŠ¸ë¦¬)

        Args:
            toc_entries: ëª©ì°¨ í•­ëª© ë¦¬ìŠ¤íŠ¸

        Returns:
            ê³„ì¸µì  ëª©ì°¨ êµ¬ì¡° (dict ë¦¬ìŠ¤íŠ¸)
        """
        # ê°„ë‹¨ ë²„ì „: í”Œë« ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜ (ë ˆë²¨ ì •ë³´ í¬í•¨)
        # í–¥í›„ íŠ¸ë¦¬ êµ¬ì¡°ë¡œ í™•ì¥ ê°€ëŠ¥

        result = []

        for entry in toc_entries:
            result.append({
                "title": entry.title,
                "level": entry.level,
                "pageNum": entry.page_num + 1,  # ì‚¬ìš©ìëŠ” 1ë¶€í„° ì‹œì‘
                "fontSize": entry.font_size,
                "confidence": entry.confidence
            })

        return result

    def detect_headings_by_reference_position(
        self,
        doc_analysis: DocumentAnalysis,
        reference_y_min: float = 65.0,
        reference_y_max: float = 75.0,
        font_size_tolerance: float = 0.5
    ) -> List[TOCEntry]:
        """
        ì°¸ì¡° ìœ„ì¹˜ ê¸°ë°˜ í—¤ë”© ê°ì§€

        íŠ¹ì • y ì¢Œí‘œ ë²”ìœ„ì— ìˆëŠ” í…ìŠ¤íŠ¸ë“¤ì˜ í°íŠ¸ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬,
        ë™ì¼í•œ í°íŠ¸ëª…ê³¼ í¬ê¸°ë¥¼ ê°€ì§„ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ëª©ì°¨ë¡œ ì‚¬ìš©

        Args:
            doc_analysis: ë¬¸ì„œ ë¶„ì„ ê²°ê³¼
            reference_y_min: ì°¸ì¡° y ì¢Œí‘œ ìµœì†Œê°’
            reference_y_max: ì°¸ì¡° y ì¢Œí‘œ ìµœëŒ€ê°’
            font_size_tolerance: í°íŠ¸ í¬ê¸° í—ˆìš© ì˜¤ì°¨

        Returns:
            ëª©ì°¨ í•­ëª© ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"ì°¸ì¡° ìœ„ì¹˜ ê¸°ë°˜ í—¤ë”© ê°ì§€ ì‹œì‘ (y: {reference_y_min}~{reference_y_max})")

        # Step 1: ì°¸ì¡° ìœ„ì¹˜ì˜ í…ìŠ¤íŠ¸ ë¸”ë¡ ì°¾ê¸°
        reference_blocks = []
        for page_analysis in doc_analysis.pages:
            for block in page_analysis.text_blocks:
                y = block.bbox.y0
                if reference_y_min <= y <= reference_y_max:
                    reference_blocks.append(block)
                    logger.info(
                        f"âœ… ì°¸ì¡° ë¸”ë¡ ë°œê²¬: '{block.text[:50]}' "
                        f"(y={y:.4f}, font={block.font.name}, size={block.font.size:.2f}pt)"
                    )

        if not reference_blocks:
            logger.warning(f"ì°¸ì¡° ìœ„ì¹˜({reference_y_min}~{reference_y_max})ì— í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©")
            return self.filter_false_positives(self.detect_headings(doc_analysis))

        logger.info(f"ì°¸ì¡° ìœ„ì¹˜ì—ì„œ {len(reference_blocks)}ê°œ ë¸”ë¡ ë°œê²¬")

        # Step 2: ì°¸ì¡° ë¸”ë¡ë“¤ì˜ í°íŠ¸ ì •ë³´ ë¶„ì„
        font_info_counts = {}
        for block in reference_blocks:
            # í°íŠ¸ëª… + í¬ê¸°ë¥¼ í‚¤ë¡œ ì‚¬ìš© (í¬ê¸°ëŠ” ë°˜ì˜¬ë¦¼)
            font_key = (block.font.name, round(block.font.size, 1))
            font_info_counts[font_key] = font_info_counts.get(font_key, 0) + 1

        # ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ í°íŠ¸ ì •ë³´ ì°¾ê¸°
        if not font_info_counts:
            logger.warning("ì°¸ì¡° ë¸”ë¡ì—ì„œ í°íŠ¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return []

        reference_font_name, reference_font_size = max(
            font_info_counts.items(),
            key=lambda x: x[1]
        )[0]

        logger.info(
            f"ì°¸ì¡° í°íŠ¸ ê²°ì •: {reference_font_name}, {reference_font_size}pt "
            f"(ì¶œí˜„ {font_info_counts[(reference_font_name, reference_font_size)]}íšŒ)"
        )

        # Step 3: ì „ì²´ ë¬¸ì„œì—ì„œ ë™ì¼í•œ í°íŠ¸ëª…ê³¼ í¬ê¸°ë¥¼ ê°€ì§„ í…ìŠ¤íŠ¸ ì°¾ê¸°
        toc_entries = []
        for page_analysis in doc_analysis.pages:
            page_num = page_analysis.page_num

            for block in page_analysis.text_blocks:
                # í°íŠ¸ëª… ì¼ì¹˜ í™•ì¸
                if block.font.name != reference_font_name:
                    continue

                # í°íŠ¸ í¬ê¸° ì¼ì¹˜ í™•ì¸ (í—ˆìš© ì˜¤ì°¨ ë‚´)
                size_diff = abs(block.font.size - reference_font_size)
                if size_diff > font_size_tolerance:
                    continue

                # í…ìŠ¤íŠ¸ í•„í„°ë§
                text = block.text.strip()

                # ë„ˆë¬´ ì§§ìœ¼ë©´ ì œì™¸
                if len(text) < 2:
                    continue

                # ìˆ«ìë§Œ ìˆìœ¼ë©´ ì œì™¸
                if text.isdigit():
                    continue

                # ëª©ì°¨ í•­ëª© ìƒì„± (ë ˆë²¨ì€ ëª¨ë‘ 1ë¡œ í†µì¼)
                toc_entry = TOCEntry(
                    title=text,
                    level=1,  # ë™ì¼ í°íŠ¸ëŠ” ëª¨ë‘ ê°™ì€ ë ˆë²¨
                    page_num=page_num,
                    font_size=block.font.size,
                    bbox_x0=block.bbox.x0,
                    bbox_y0=block.bbox.y0,
                    confidence=0.95  # ì°¸ì¡° ê¸°ë°˜ì´ë¯€ë¡œ ë†’ì€ ì‹ ë¢°ë„
                )

                toc_entries.append(toc_entry)

                logger.info(
                    f"ğŸ“ ëª©ì°¨ í•­ëª© ì¶”ê°€: '{text}' "
                    f"(í˜ì´ì§€ {page_num}, y={block.bbox.y0:.4f}, font={block.font.name}, size={block.font.size:.2f}pt)"
                )

        logger.info(f"ì´ {len(toc_entries)}ê°œ ëª©ì°¨ í•­ëª© ë°œê²¬ (ì°¸ì¡° í°íŠ¸ ê¸°ë°˜)")

        # Step 4: ì¤‘ë³µ ì œê±° (ë™ì¼ í…ìŠ¤íŠ¸ê°€ ì—¬ëŸ¬ ë²ˆ ë‚˜ì˜¤ëŠ” ê²½ìš°)
        filtered = self.filter_duplicates(toc_entries)

        return filtered

    def filter_duplicates(self, toc_entries: List[TOCEntry]) -> List[TOCEntry]:
        """
        ì¤‘ë³µëœ ì œëª© ì œê±° (ê°™ì€ ì œëª©ì´ ì—¬ëŸ¬ í˜ì´ì§€ì— ë‚˜ì˜¤ëŠ” ê²½ìš° ì²« ë²ˆì§¸ë§Œ ìœ ì§€)

        Args:
            toc_entries: ëª©ì°¨ í•­ëª© ë¦¬ìŠ¤íŠ¸

        Returns:
            ì¤‘ë³µ ì œê±°ëœ ëª©ì°¨ í•­ëª© ë¦¬ìŠ¤íŠ¸
        """
        seen_titles = set()
        filtered = []

        for entry in toc_entries:
            if entry.title not in seen_titles:
                seen_titles.add(entry.title)
                filtered.append(entry)
            else:
                logger.debug(f"ì¤‘ë³µ ì œê±°: '{entry.title}'")

        logger.info(f"ì¤‘ë³µ ì œê±°: {len(toc_entries)} â†’ {len(filtered)}")
        return filtered

    def filter_false_positives(
        self,
        toc_entries: List[TOCEntry]
    ) -> List[TOCEntry]:
        """
        ê±°ì§“ ì–‘ì„±(false positive) ì œê±°

        - ë™ì¼í•œ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ë§ì´ ë°˜ë³µë˜ë©´ í—¤ë”/í‘¸í„°ì¼ ê°€ëŠ¥ì„±
        - ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ (ì˜ˆ: "1", "A")
        - ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°

        Args:
            toc_entries: ëª©ì°¨ í•­ëª© ë¦¬ìŠ¤íŠ¸

        Returns:
            í•„í„°ë§ëœ ëª©ì°¨ í•­ëª© ë¦¬ìŠ¤íŠ¸
        """
        filtered = []

        # í…ìŠ¤íŠ¸ ë¹ˆë„ ê³„ì‚°
        text_counts = {}
        for entry in toc_entries:
            text_counts[entry.title] = text_counts.get(entry.title, 0) + 1

        for entry in toc_entries:
            # ë™ì¼ í…ìŠ¤íŠ¸ê°€ 5íšŒ ì´ìƒ ë°˜ë³µë˜ë©´ ì œì™¸ (í—¤ë”/í‘¸í„°)
            if text_counts[entry.title] >= 5:
                logger.debug(f"ê±°ì§“ ì–‘ì„± ì œê±° (ë°˜ë³µ): {entry.title}")
                continue

            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ì œì™¸ (2ê¸€ì ë¯¸ë§Œ)
            if len(entry.title.strip()) < 2:
                logger.debug(f"ê±°ì§“ ì–‘ì„± ì œê±° (ì§§ìŒ): {entry.title}")
                continue

            # ìˆ«ìë§Œ ìˆìœ¼ë©´ ì œì™¸
            if entry.title.strip().isdigit():
                logger.debug(f"ê±°ì§“ ì–‘ì„± ì œê±° (ìˆ«ìë§Œ): {entry.title}")
                continue

            filtered.append(entry)

        logger.info(f"ê±°ì§“ ì–‘ì„± ì œê±°: {len(toc_entries)} â†’ {len(filtered)}")
        return filtered


# í¸ì˜ í•¨ìˆ˜
def detect_headings_from_pdf(pdf_path: str) -> List[TOCEntry]:
    """
    PDFì—ì„œ í—¤ë”© ê°ì§€ (í¸ì˜ í•¨ìˆ˜)

    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ

    Returns:
        ëª©ì°¨ í•­ëª© ë¦¬ìŠ¤íŠ¸
    """
    from app.services.pdf_analyzer import analyze_pdf

    # PDF ë¶„ì„
    doc_analysis = analyze_pdf(pdf_path)

    # í—¤ë”© ê°ì§€
    detector = HeadingDetector()
    toc_entries = detector.detect_headings(doc_analysis)

    # ê±°ì§“ ì–‘ì„± ì œê±°
    toc_entries = detector.filter_false_positives(toc_entries)

    return toc_entries


# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸
if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python heading_detector.py <pdf_file_path>")
        sys.exit(1)

    pdf_file = sys.argv[1]

    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO)

    # í—¤ë”© ê°ì§€
    toc_entries = detect_headings_from_pdf(pdf_file)

    # ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"í—¤ë”© ê°ì§€ ê²°ê³¼: ì´ {len(toc_entries)}ê°œ")
    print(f"{'='*60}\n")

    for i, entry in enumerate(toc_entries, 1):
        indent = "  " * (entry.level - 1)
        print(
            f"{indent}{i}. [Level {entry.level}] {entry.title} "
            f"(í˜ì´ì§€ {entry.page_num + 1}, {entry.font_size:.1f}pt, "
            f"ì‹ ë¢°ë„ {entry.confidence:.2f})"
        )